{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/shir994/misis_seminars/blob/master/MiSiS_ldm_seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKZX8Z990nmP"
   },
   "source": [
    "In this seminar we will examine the toy data for simulation of the LDM and neutrino scattering inside SND detector. All data presented here are Monte Carlo truth data. You task will be to plot some plots, make some guesses and train basic algorithms to try to distinguish between LDM events and neutrino based on observed MC variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "M19M-K7yw8la",
    "outputId": "f322ef52-cb59-455b-c3d4-65bab1e9618d"
   },
   "outputs": [],
   "source": [
    "!wget -O dm_kinematics.pkl https://cernbox.cern.ch/index.php/s/Sw18OVFaIUcafus/download\n",
    "!wget -O nu_e_elastic_kinematics.pkl https://cernbox.cern.ch/index.php/s/pQ2EnbWgY12tT3D/download\n",
    "!wget -O nu_ccqe_elastic_kinematics.pkl https://cernbox.cern.ch/index.php/s/5w73TtuwUjMoTMp/download  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcmJTOZYvJ61"
   },
   "outputs": [],
   "source": [
    "# Importing all the necessary packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['hatch.linewidth'] = 2.0\n",
    "my_cmap = plt.cm.jet\n",
    "my_cmap.set_under('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_hGLju-vJ6_"
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        raw_data = pickle.load(f)\n",
    "    \n",
    "    dict_data = {\"init_E\":[], \"ele_E\": [], \"ele_theta\": [], \"ele_theta_to_particle\": [], \"init_theta\":[]}\n",
    "    for event in raw_data:\n",
    "        if len(event) == 2:\n",
    "            dict_data[\"init_E\"].append(event['initial_particle']['E'])\n",
    "            dict_data[\"init_theta\"].append(event[\"initial_particle\"][\"theta\"])           \n",
    "            dict_data[\"ele_E\"].append(event[\"ele_params\"][\"E\"])\n",
    "            dict_data[\"ele_theta\"].append(event[\"ele_params\"][\"theta\"])\n",
    "            dict_data[\"ele_theta_to_particle\"].append(event[\"ele_params\"][\"theta_to_particle\"])\n",
    "    return pd.DataFrame(dict_data, columns=[\"init_E\", \"ele_E\", \"ele_theta\", \"ele_theta_to_particle\", \"init_theta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRgNTHpZvJ7I"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "dm_df = read_file(\"dm_kinematics.pkl\")\n",
    "nu_df_el = read_file(\"nu_e_elastic_kinematics.pkl\")\n",
    "nu_df_ccqe = read_file(\"nu_ccqe_elastic_kinematics.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrQcCqPz1bvS"
   },
   "source": [
    "## Examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fuEs4Ujyoh_"
   },
   "source": [
    "Ok, we have donwloaded our data. Lets have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "TfpTjNcPy2Lw",
    "outputId": "b22edc28-0d03-4e49-b467-b6ebe16c9bf9"
   },
   "outputs": [],
   "source": [
    "dm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzeLLyv4zDq9"
   },
   "source": [
    "We have five initial features\n",
    "- init_E - energy of neutrino\n",
    "- init_theta - angle of neutrino wrt to Z-axis\n",
    "- ele_E - energy of outgoing electron\n",
    "- ele_theta - angle of outgoing electron wrt to Z-asis\n",
    "- ele_theta_to_particle - angle of outgoing electron wrt to direction of neutrino \n",
    "\n",
    "What do you think we can actually observe in the detector? Can we approximate other variables somehow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot some features to compare distributions for LDM and neutrino events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots for EL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_plots(dm_data, nu_data, xlabel=None, x_range=None, nu_label=\"Elastic\"):\n",
    "    plt.hist(dm_data, density=True, bins=50, label=\"DM\", range=x_range,\n",
    "             edgecolor='k', hatch='/', fill=False, histtype='step', linewidth=5)\n",
    "    plt.hist(nu_data, density=True, bins=50, alpha=0.5, label=r\"{} $\\nu_e$\".format(nu_label), range=x_range,\n",
    "             edgecolor='k', hatch='x', fill=False, histtype='step', linewidth=5)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=30)\n",
    "    plt.xlabel(xlabel, fontsize=25);\n",
    "    plt.ylabel(\"a.u.\", fontsize=25)\n",
    "    plt.tick_params('both', labelsize=20)\n",
    "    \n",
    "plt.figure(figsize=(32, 8))\n",
    "plt.subplot(1,3,1)\n",
    "add_plots(dm_df[\"ele_E\"], nu_df_el[\"ele_E\"], \"Electron  $E$, GeV\",x_range=(0,30))\n",
    "plt.subplot(1,3,2)\n",
    "add_plots(dm_df[\"ele_theta\"], nu_df_el[\"ele_theta\"], r\"Electron $\\theta$, rad\",x_range=(0, 0.05))\n",
    "plt.subplot(1,3,3)\n",
    "add_plots(dm_df[\"ele_theta_to_particle\"], nu_df_el[\"ele_theta_to_particle\"],\n",
    "          r\"Electron $\\theta$ wrt to $\\nu$, rad\", x_range=(0, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots for CCQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32, 8))\n",
    "plt.subplot(1,3,1)\n",
    "add_plots(dm_df[\"ele_E\"], nu_df_ccqe[\"ele_E\"], \"Electron  $E$, GeV\",x_range=(0,30), nu_label=\"CCQE\")\n",
    "plt.subplot(1,3,2)\n",
    "add_plots(dm_df[\"ele_theta\"], nu_df_ccqe[\"ele_theta\"], r\"Electron $\\theta$, rad\",x_range=(0, 0.05), nu_label=\"CCQE\")\n",
    "plt.subplot(1,3,3)\n",
    "add_plots(dm_df[\"ele_theta_to_particle\"], nu_df_ccqe[\"ele_theta_to_particle\"],\n",
    "          r\"Electron $\\theta$ wrt to $\\nu$, rad\", x_range=(0, 0.05), nu_label=\"CCQE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like for CCQE its quite hard to distinguish, lets plot 2d hists!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now its your turn to quickly draw some plots.\n",
    "- Using the code above plot 2D histogram(use *plt.hist2d*) of electron energy (\"ele_E\") vs electron angle (\"ele_theta\") for LDM, EL, CCCQE\n",
    "- Sacle histogram to be in the same size in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MsgIEHTvJ7e",
    "outputId": "4d900724-3e4a-4a88-8bea-9ddf68d2c3f2"
   },
   "outputs": [],
   "source": [
    "def add_plots(dm_data, nu_data, xlabel=None, title=None):\n",
    "    <YOUR CODE>\n",
    "    \n",
    "plt.figure(figsize=(33, 8))\n",
    "plt.subplot(1,3,1)\n",
    "add_plots(dm_df[\"ele_E\"], dm_df[\"ele_theta\"], xlabel=\"Electron  $E$, GeV\", title=\"LDM\")\n",
    "plt.subplot(1,3,2)\n",
    "add_plots(nu_df_el[\"ele_E\"], nu_df_el[\"ele_theta\"], xlabel=\"Electron  $E$, GeV\", title=\"Elastic\")\n",
    "plt.subplot(1,3,3)\n",
    "add_plots(nu_df_ccqe[\"ele_E\"], nu_df_ccqe[\"ele_theta\"], xlabel=\"Electron  $E$, GeV\", title=\"CCQE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? How can we improve this very basic visual analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikEy19MlvJ8O"
   },
   "source": [
    "# Fit some simple ML algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets use the very basic alogirthms to decide what is LDM and what is noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqIVL4GavJ8P"
   },
   "outputs": [],
   "source": [
    "# import packages we want to use\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_df.shape, nu_df_el.shape, nu_df_ccqe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "puJoT6l7vJ8S"
   },
   "outputs": [],
   "source": [
    "def perpare_data(dm_df, nu_df_el, nu_df_ccqe):\n",
    "    # We subsample data to make equal proportion of LDM events(signal) and ne_e elastic(background)\n",
    "    # This is done for our metrics to be representative\n",
    "    dm_df_sample = dm_df.sample(n=nu_df_el.shape[0], random_state=1543)\n",
    "    \n",
    "    # Label data\n",
    "    dm_df_sample['label'] = 1\n",
    "    nu_df_el['label'] = 0\n",
    "    nu_df_ccqe['label'] = 2\n",
    "\n",
    "    # and join in aggregative table\n",
    "    joined_data = pd.concat((dm_df_sample, nu_df_el, nu_df_ccqe))\n",
    "    joined_data = joined_data.sample(frac=1, replace=False)    \n",
    "    print(joined_data.head())\n",
    "    \n",
    "    # Separate label from our discriminative features\n",
    "    y = joined_data['label']\n",
    "    joined_data = joined_data.drop(['label'], axis=1)\n",
    "    ccqe_indeces = np.where(y==2)[0]\n",
    "    y[y==2] = 0\n",
    "    return joined_data, y, ccqe_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data, y, ccqe_indeces = perpare_data(dm_df, nu_df_el, nu_df_ccqe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuURaD32vJ8_"
   },
   "source": [
    "# !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as for a bare curiosity lets first train algortihm only using one feature - energy of the electron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfK_UdpbvJ9A",
    "outputId": "3116bd85-2f0b-4496-c3fe-d890c821409f"
   },
   "outputs": [],
   "source": [
    "# This is current columns of the dataset\n",
    "joined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only init_E column in a separate variable, name it e_only_train\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The output of our algo will be probabilities of an event to belong to class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.001)\n",
    "\n",
    "probs = cross_val_predict(model, e_only_train, y=y, cv=5, n_jobs=4, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probs[:,1]);\n",
    "plt.xlabel(\"Probability\", fontsize=25)\n",
    "plt.ylabel(\"a.u.\", fontsize=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very inforomative right? Of course, in physics we have a stanard metrics how we can define the performance of the algorigthm, for example, $\\frac{S}{\\sqrt{B}}$. In our case we will consider signal efficiency VS background rejection. Sklearn has inbulid functions to calculate to calculate almost what we need, just defined in mathematical terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,t = roc_curve(y.values, probs[:, 1], pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above returns False Positive Rate(FPR) which is defined as:\n",
    "$$\n",
    "FPR = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "and True Positive Rate(TPR) which is defined as\n",
    "$$\n",
    "TPR = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "This definitions are basically what we need? How do they correspond to signal efficiency and background rejection? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the dependecy of signal efficiency VS background rejection as a curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "<YOUR CODE>\n",
    "\n",
    "plt.xlabel(\"Background rejection efficiency (EL + CCQE)\", fontsize=25)\n",
    "plt.ylabel(\"Signal efficiency\", fontsize=25);\n",
    "print(\"AVG precision\", average_precision_score(y.values, probs[:, 1], pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat expected, isnt it? As you can see, the quality is qutie low. This was obious for the initial plots, we have plotted in the beginning. Now lets now repeat the procedure, using all the features we have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_plot(model, data, y):\n",
    "    probs = cross_val_predict(model, data, y=y, cv=5, n_jobs=4, method='predict_proba')\n",
    "    fpr,tpr,t = roc_curve(y.values, probs[:, 1], pos_label=1)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(1 - fpr, tpr)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Background rejection efficiency (EL + CCQE)\", fontsize=25)\n",
    "    plt.ylabel(\"Signal efficiency\", fontsize=25);\n",
    "    print(\"AVG precision\", average_precision_score(y.values, probs[:, 1], pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.001)\n",
    "fit_and_plot(model, joined_data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, isnt it? But, do we have some features, we usually use in physics, that we can create from the given data? YES! We can can create, for example, $E_T$. So, add $E_T$ to the data and refit the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.001)\n",
    "fit_and_plot(model, joined_data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can try different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=500)\n",
    "feature_columns = ['ele_E', 'ele_theta', 'ele_theta_to_particle', 'E_t', \"init_theta\", \"E_t_rel\"]\n",
    "fit_and_plot(model, joined_data[feature_columns], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAY much better out of the box!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=500)\n",
    "probs = cross_val_predict(model, joined_data[feature_columns], y=y, cv=5, n_jobs=4, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(probs[y.values == 0, 1], bins=50, label='nu')\n",
    "plt.hist(probs[y.values == 1, 1], bins=50,alpha=0.5, label='dm');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also study answer distribution and go into the depth of the why we get this particular answers,\n",
    "sample data in the right propotion to the reaction cross-secition and etc. All the above is just a toy example to give you and idea what is day to day task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus quest: try to do GridSearch and improve the resuls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M01nQhGKvJ-j",
    "outputId": "bc94b61e-3f11-4496-aba1-f0f4e109c113"
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(model, param_grid={\"C\": np.logspace(-3, 3, 10)}, scoring=\"roc_auc\", n_jobs=3, cv=5)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OC5QwlJfvJ-q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwMZ0AGPvJ-r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MiSiS_ldm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
